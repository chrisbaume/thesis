% !TeX root = main.tex
\chapter{Introduction}\label{chp:intro}

Want to improve interface for professionally working with audio content

Semantic audio analysis can extract useful information, but how can this best be used?

Tasks are creative, so can't easily be automated

Humans and machines working to their strengths

Inspired by \citet{Loviscach2013}

\section{Background and motivation}\label{sec:intro-motivation}

This thesis focusses on the production of ``radio'', which we define as the broadcasting of sound programmes to the
public.  Radio can also be defined as the transmission of sound using radio waves, and a device used to transmit or
receive radio signals.  However, our work is concerned with the production of content, rather than the method of
delivery.

Radio broadcasting is a mass medium.  A quarterly survey of over 24,000 adults in the UK \citep{RAJAR2017a} found that
90\% of the UK adult population listen to the radio each week for an average of 21 hours. The results also showed that
BBC Radio has the largest share of radio listening in UK, with 64\% listening each week for an average of 16 hours.

Although most radio listening is done live, the advent of the Internet has enabled listeners to download pre-produced
audio content, known as ``podcasts''. A detailed survey of 2229 UK adults on the consumption of audio content
\citep{RAJAR2017} found that each week, 10\% listened to podcasts. 

Ever since the first digital audio workstations were introduced in the early
1990s, the audio waveform has been the primary method of navigating audio
content. The waveform works well for finding amplitude-related events such as
silences and peaks, but is very poor at conveying much more about the sound of
the content. Additionally, the waveform doesn't scale well as demonstrated by
the `Soundcloud sausage' (see Figure~\ref{fig:soundcloud}), where even at
reasonable zoom levels, no useful information is presented.  A popular
alternative to the waveform is the spectrogram, which displays detailed
information about the frequency content. However, these can be very difficult
to interpret and require training and practice to be of use.

\section{Research questions and scope}\label{sec:intro-questions}
This projects aims to develop better visualization for helping radio producers
navigate audio content by initially targeting a number of common tasks. Audio
features will be identified or developed which are able to capture the
information required for the task. Methods of mapping these features to an
image will be created so that the information is presented in a perceptible way
which requires little or no training. 

\subsection{Sound}
% Sound is linear - has a beginning and an end, constrained by the arrow of time
% Cannot be searched or skimmed
% Sound is one-dimensional
% We never stop listening
% Huge range of frequencies and pressure levels

%Audio is an electronic representation of sound which stores pressure waves as an electrical signal.

% Characteristics of sound
One of the distinuishing characters of radio is that it is based exclusively on sound.
Sound is defined as vibrations that travel through a medium, typically air, which humans perceive through their ears.
As it is based on vibration, sound cannot exist in a moment -- it can only take place over a period of time.
Sound is linear, as it is based on a sequence of motion.
It is experienced at a consistent rate, which cannot naturally be increased or desreased.

% challenges of sound
This time-based nature of sound gives it a fascinating character.
However, the time-based nature of sound comes with a variety of challenges.
Sound cannot be experienced instantanously, as it is the change in air pressure which produces sound.
As such, it takes time to consume sound.
For consuming long sound recordings, this property means that listening requires an investment of time.
In radio production, much of the time required to produce a programme must be committed to listening to the sound that has been recorded.
%The purpose of listening to the sound includes a variety of reasons, including reminding themselves of what
%was said, working out whether the sound quality is acceptable, deciding which bits of the recording to use, and many
%more.

To overcome the challenges that come with the temporal nature of sound, there are a number of technological solutions
that can be applied. At the very simplest level, sound can be navigated using rewind and fast-forward, to allow
listeners to re-listen or skip ahead to a sound recording. The playback rate of sound recordings can also be increased,
but there are limitations to this, which we discuss in Section X. However, in order to navigate sound with purpose, it
is preferable to be able to understand what is contained within the sound, and to be able to comprehend this
information efficiently. There have been two main approaches to achieving this -- audio visualization and semantic
audio analysis.

%From Dhanesha2010:
%It is a common practice for us to skim textual content on a web page. While skimming, we usually skip words or phrases
%that are not of interest to us and we slow down our speed when the content seems to be of relevance to us. But when we
%listen to audio content, which is not persistent and is sequential, such skimming is not possible.

Audio visualization attempts to take advantage of the properties of the human visual system by mapping sound to images.
This is done to allow listeners to see the sound in a way they can understand and make use of. This approach takes
advantage of the spatial layout that is possible with images, and the natural searching and skimming capabilities of
the human visual system.

Semantic audio analysis refers to a collection of techniques for analysing sound signals to extract human-readable
information from them. This can be used to map sound to high-level information, such as the name of the person
speaking, or the text of what they are saying. These techniques can vary from low-level features such as the most
dominant frequency, to high-level features such as the text of the words that are being spoken. These techniques can
also be combined with visualization methods to display the results.

As part of this work, we want
to understand how these techniques can best be applied to the production of radio, and make the process more efficient
by reducing the time that is needed to produce the programme. 

\section{Scope}

% SCOPE
% - only consider audio-only content, no pictures with radio
% - do not include tools for automatically editing (computer based decisions)
% - not including live production, which is already efficient
% - speech, not music
% - interested in reviewing technology that aids navigation and editing of audio
% - navigating/editing within a single file, rather than navigating a collection of material

%Stolen: In this chapter, we can find a review of a variety of systems and technologies that are related to the
%approach we have chosen for our search interface. It is organized in sections according to different research fields
%that play an important role on our proposed system.

% Focus on pre-produced radio
Most radio is produced live, where a number of audio sources are mixed together and broadcast to the listeners.
Although a lot of planning and preparation goes into a live transmission, the actual audio production happens in
real-time, so there is no opportunity to improve the efficiency of the audio production. However, many radio programmes
are pre-produced, where the sound is recorded before transmission.  In these cases, audio editing is used to manipulate
the recordings to remove unwanted parts of the recording, select particularly good parts, or mix the recording with
other recordings. This process creates overheads for the producers, who must use a set of tools to create their
programme. This audio editing process creates opportunities to make the audio production process more efficient. For
this reason, we chose to focus our research on pre-produced programmes and the audio editing stage of radio production.


\section{Thesis structure}\label{sec:intro/structure}

\paragraph{Chapter \ref{chp:background}} reviews existing work and literature from three areas that will feed into the
project -- feature extraction, visualization and cross-modal links.

\paragraph{Chapter \ref{chp:ethno}} describes an ethnographic study that provides a comprehensive overview of the radio
production process at the BBC, which will help put this research into context.

\paragraph{Chapter \ref{chp:colourised}} presents a quantitative study that looked at how the waveform performs in a
common production tasks, and whether it can be improved.

\paragraph{Chapter \ref{chp:screen}} uses a qualitative study to investigate how a screen-based semantic audio editing
interface affects the production process.

\paragraph{Chapter \ref{chp:paper}} describes a qualitative study that investigates how a paper-based semantic audio
editing interface compares to the screen-based approach and normal paper.

\paragraph{Chapter \ref{chp:conclusions}} concludes the thesis and considers the prospects for future research.

\section{Contributions}\label{sec:intro-contributions}

The principal contributions of this thesis are:
\begin{itemize}
  \item Chapter~\ref{chp:colourised}: 
  \item Chapter~\ref{chp:ethno}: 
  \item Chapter~\ref{chp:screen}: 
  \item Chapter~\ref{chp:paper}: a novel system for editing speech-based audio using digital pens on printed transcripts
\end{itemize}

\section{Associated publications}\label{sec:intro-publications}

Portions of the work detailed in this thesis have been presented in the following publications:

\subsection*{Conference papers}

\begin{itemize}
  \item Chapter~\ref{chp:ethno}: Published and presented at the 138th Audio Engineering Society convention in Warsaw,
    Poland \citep{Baume2015}
\end{itemize}

\subsection*{Software releases}
As part of this research, we have developed and released the following systems as open-source software:

\begin{itemize}
  \item \textbf{Dialogger}: A semantic speech editing system (see Appendix~\ref{sec:dialogger})
  \item \textbf{Vampeyer}: An audio visualization plugin framework (see Appendix~\ref{sec:vampeyer})
  \item \textbf{BeatMap}: An audio visualization UI element for web browsers (see Appendix~\ref{sec:beatmap})
\end{itemize}

