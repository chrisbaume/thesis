% !TeX root = main.tex
\chapter{Introduction}\label{chp:intro}

Want to improve interface for professionally working with audio content

Semantic audio analysis can extract useful information, but how can this best be used?

Tasks are creative, so can't easily be automated

Humans and machines working to their strengths

Inspired by \citet{Loviscach2013}

\section{Background and motivation}\label{sec:intro-motivation}

This thesis focusses on the production of ``radio'', which we define as the broadcasting of sound programmes to the
public.  Radio can also be defined as the transmission of sound using radio waves, and a device used to transmit or
receive radio signals.  However, our work is concerned with the production of content, rather than the method of
delivery.

Radio broadcasting is a mass medium.  A quarterly survey of over 24,000 adults in the UK \citep{RAJAR2017a} found that
90\% of the UK adult population listen to the radio each week for an average of 21 hours. The results also showed that
BBC Radio has the largest share of radio listening in UK, with 64\% listening each week for an average of 16 hours.

Although most radio listening is done live, the advent of the Internet has enabled listeners to download pre-produced
audio content, known as ``podcasts''. A detailed survey of 2229 UK adults on the consumption of audio content
\citep{RAJAR2017} found that each week, 10\% listened to podcasts. 

Ever since the first digital audio workstations were introduced in the early
1990s, the audio waveform has been the primary method of navigating audio
content. The waveform works well for finding amplitude-related events such as
silences and peaks, but is very poor at conveying much more about the sound of
the content. Additionally, the waveform doesn't scale well as demonstrated by
the `Soundcloud sausage' (see Figure~\ref{fig:soundcloud}), where even at
reasonable zoom levels, no useful information is presented.  A popular
alternative to the waveform is the spectrogram, which displays detailed
information about the frequency content. However, these can be very difficult
to interpret and require training and practice to be of use.

\section{Research questions and scope}\label{sec:intro-questions}
This projects aims to develop better visualization for helping radio producers
navigate audio content by initially targeting a number of common tasks. Audio
features will be identified or developed which are able to capture the
information required for the task. Methods of mapping these features to an
image will be created so that the information is presented in a perceptible way
which requires little or no training. 

\section{Scope}

% SCOPE
% - only consider audio-only content, no pictures with radio
% - do not include tools for automatically editing (computer based decisions)
% - not including live production, which is already efficient
% - speech, not music
% - interested in reviewing technology that aids navigation and editing of audio
% - navigating/editing within a single file, rather than navigating a collection of material

%Stolen: In this chapter, we can find a review of a variety of systems and technologies that are related to the
%approach we have chosen for our search interface. It is organized in sections according to different research fields
%that play an important role on our proposed system.

% Focus on pre-produced radio
Most radio is produced live, where a number of audio sources are mixed together and broadcast to the listeners.
Although a lot of planning and preparation goes into a live transmission, the actual audio production happens in
real-time, so there is no opportunity to improve the efficiency of the audio production. However, many radio programmes
are pre-produced, where the sound is recorded before transmission.  In these cases, audio editing is used to manipulate
the recordings to remove unwanted parts of the recording, select particularly good parts, or mix the recording with
other recordings. This process creates overheads for the producers, who must use a set of tools to create their
programme. This audio editing process creates opportunities to make the audio production process more efficient. For
this reason, we chose to focus our research on pre-produced programmes and the audio editing stage of radio production.


\section{Thesis structure}\label{sec:intro/structure}

\paragraph{Chapter \ref{chp:background}} reviews existing work and literature
from three areas that will feed into the project -- feature extraction,
visualization and cross-modal links.

\paragraph{Chapter \ref{chp:colourised}} details the process and results of an
initial online study which looked at how the waveform performs in a common
production tasks, and whether it can be improved.

\paragraph{Chapter \ref{chp:ethno}} provides a comprehensive overview of
the radio production process at the BBC, which will help put this research into
context.

\paragraph{Chapter \ref{chp:screen}} investigates how a screen-based semantic audio editing interface affects the
production process.

\paragraph{Chapter \ref{chp:paper}} investigates how a paper-based semantic audio editing interface compares to
the screen-based approach and normal paper.

\paragraph{Chapter \ref{chp:conclusions}} concludes the thesis and considers the prospects for future research.

\section{Contributions}\label{sec:intro-contributions}

The principal contributions of this thesis are:
\begin{itemize}
  \item Chapter~\ref{chp:colourised}: 
  \item Chapter~\ref{chp:ethno}: 
  \item Chapter~\ref{chp:screen}: 
  \item Chapter~\ref{chp:paper}: a novel system for editing speech-based audio using digital pens on printed transcripts
\end{itemize}

\section{Associated publications}\label{sec:intro-publications}

Portions of the work detailed in this thesis have been presented in the following publications:

\subsection*{Conference papers}

\begin{itemize}
  \item Chapter~\ref{chp:ethno}: Published and presented at the 138th Audio Engineering Society convention in Warsaw,
    Poland \citep{Baume2015}
\end{itemize}

\subsection*{Software releases}
As part of this research, we have developed and released the following systems as open-source software:

\begin{itemize}
  \item \textbf{Dialogger}: A semantic speech editing system (see Appendix~\ref{sec:dialogger})
  \item \textbf{Vampeyer}: An audio visualization plugin framework (see Appendix~\ref{sec:vampeyer})
  \item \textbf{BeatMap}: An audio visualization UI element for web browsers (see Appendix~\ref{sec:beatmap})
\end{itemize}

