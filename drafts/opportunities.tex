\section{Research opportunities}
The information obtained during the process of preparing
Section~\ref{sec:production} has identified a number of opportunities for
improving the production workflow through the application of semantic audio
analysis and human computer interaction techniques. Short descriptions of these
are listed below.

\paragraph{Audio visualisation}
In the software mentioned above, and in all digital audio workstations, audio
data is represented as an amplitude waveform. The simplicity and age of this
visualisation means that it is easily understood and its use is widespread.

Amplitude waveforms are convenient for finding silences and measuring peaks,
and can be used to identify audio content with characteristic amplitude
envelopes (e.g. drums, speech). BBC studio managers with decades of experience
have reportedly learnt to identify a much wider range of content, such as
laughter.  However, waveforms are very restricted in the information they can
portray -- there is no data about the frequency content, for example. 

By taking into account what users are trying to achieve and how they interpret
visual representation of audio, it may be possible to create a better
alternative to the existing amplitude waveform. Such a visualisation would
attempt to make full use of the visual system by using shape, colour and
texture. It could be designed to be task-specific, such as for identifying
different speakers in speech content, or generic, which could be used for a
variety of tasks.

\paragraph{Vocal stop}
There are a couple of scenarios in which it would be useful for presenters to
know which parts of a recording they are able to talk over or not. For
instance, when a DJ starts playing a song, it would be beneficial for them to
know how much time they have remaining before the intro finishes and the song
`kicks-in'. Traditionally, this is done when the music is ingested by marking
the `vocal stop' point.

Another example of this being required is for continuity announcers.
Particularly when they are trying to keep to schedule, it would be useful for
them to know which parts of a programme intro/outro can be spoken over.

When ingesting music content, often vocal stop information is added in
manually. For instance, this feature is built into the Selector music
scheduling software used by Global Radio. This means that there is a sizeable
database of ground truth data that could be used with a machine learning
algorithm.

\paragraph{Fast forward}
The fast-forward functionality of programs like StarTrack and Orion (accessible
with the \texttt{[$\uparrow$]} and \texttt{[$\downarrow$]} keys) is used widely
to skim recordings of speech. Often this is done by the person who made the
recording to find moments referred to in their notes. One producer was
frustrated by the fast-forward being limited to double-speed and requested that
faster speech skimming was made available.

Increasing the playback speed of speech whilst retaining intelligibility is
known as `speech skimming'. The seminal work from Arons \citep{Arons1997} lists
five techniques for speech skimming, including pause shortening/removal,
skipping 30-50ms segments with/without overlapping and dichotic sampling
(playing odd/even segments in the left/right ear). These techniques could be
used to try and progress beyond ``the 2x perceptual barrier typically
associated with time-scaling speech''.

\paragraph{Music summarisation for podcasts}
After transmission, some programmes are turned into podcasts, which allows
listeners to download content permanently. Each podcast requires a BBC intro
and outro to be added to the recording, and for each music track in the
programme to be cut to 30 seconds for rights reasons.

Typically, the first 30 seconds of the track are used before it is faded out.
However, this is often not a fair representation of the track as it can skip
out the most characteristic parts of the music, known as the `hook'.

It should be possible to automatically summarise music tracks in 30 seconds
using audio analysis algorithms to give a better representation than a fixed
time selection. This technology could also be applied to online music services,
which often provide a 30s sample so that customers can decide whether to buy a
track.

\paragraph{Swearing detector}
Radio 1 showed interest in a swear word detector, which would flag up potential
profanity in recordings. This could mean that producers would only have to
listen to the top/tail of a recording before being able to broadcast it.
Without such a detector, they would have to listen to the entire recording to
ensure it was suitable, delaying the turnaround time.

\paragraph{Acoustic markers}
After on-site recordings are made, many producers listen back through the
recording to create markers at notable points in the interview. Usually, these
points have already been noted on paper as the interview was recorded. It may
be useful to be able to mark recordings as they are made, which could be done
by using a high frequency tone emitted from a mobile phone or similar device.
The frequencies used would be imperceptible to most people and would be
automatically filtered out in the broadcast chain. However, it would be
detectible by software which could automatically place markers at those
locations.

\paragraph{Smart cursor}
When editing audio content, producers are normally using a zoom level that does
not allow fine selection of edit points. Because of this, when content is cut
there is a risk that the cut will be made at an unsuitable point, which can
cause problems such as clicks. Normally this can be solved using crossfading,
but it may be wiser to create a `smart cursor' that snaps to points which make
appropriate cutting points. For instance, silences or zero-crossing points
generally make good cutting points. In the case of selecting a region of audio
for deletion, the endpoint could snap to a place that would mix well with the
beginning of the selection, such one that maintains a constant rhythm when
shortening a music track.

\paragraph{Variable length}
In news production, it is common for producers to be required to deliver news
reports in a variety of lengths so that they can be fitted into the dynamic
programme schedule, even when it shifts.

